Doel:
Charitius 2.0
Een open data set van goede doelen pakken en deze zoekbaar maken.
Eerst alleen op titel, dan ook 'full-text' indexing.

Als het ok werkt, dan ook op Digital Ocean deployen. 
Als dat ok werkt, dan steeds meer open data toevoegen.
Geen webscraping, maar alleen van officiele bronnen.

USA2:
  - Aanname is nu dat het es.json bestand gewoon te groot was
    x Test met 10 regels toont dat deze upload werkt
    x Test met 100.000 regels toont dat uploaden werkt
    x Script voor split in telkens 100.000 regels
    x Upload script aanpassen om split gegenereerde bestanden te gebruiken
    - Makefile aanpassen 
      - ook die splits doen
      - upload met juiste variabele (gaat misschien vanzelf goed)
  - Meer csv bestanden, scripts lijken te werken, maar upload faalt
    usa/es.json faalt niet, dus iets is anders/fout aan usa2/es.json
    - TODO: check of uberhaubt juiste kolommen gepakt worden.
Error is
 {"error":{"root_cause":[{"type":"illegal_argument_exception","reason":"The bulk request must be terminated by a newline [\\n]"}],"type":"illegal_argument_exception","reason":"The bulk request must be terminated by a newline [\\n]"},"status":400}

Flask:
  x Flask image maken
  - Flask image opschonen, niet copy . /app want volume mapping
  - Starten met docker-compose en volume mapping
      - In zelfde network ook Flask
      - Eerst met standaardserver van Flask
  - Basis pagina (van charitius code overnemen)
  - Flask laten praten met Elastic
  - Data uitlezen met Flask met Flask

Zoek verbeteren:
Mogelijke feature van zoekmachine is dat je veel kunt customizen
Dat je bijv. zelf fuzziness kunt selecteren, etc.
  - Land filteren
  - Fuzzy
  - Misschien tokenizen
  - Kibana voor monitoring kan ook nuttig zijn

Log:
   - Moet ook wegschrijven in een .log bestand 
     Dat bijhoudt waneer welk bestand gemaakt is e.d.

Betere scripts:
 - Opschonen scripts (alles met python argv paden)
 - Bewaar niet meer tussenstappen, maar wel het raw bestand?
   Liefst variant met copy met datum stamp
   Dus dat die backup wel bewaard blijft, maar niet bronbestand
 - SourceURL en SourceDate in een soort config bestand ergens zetten
   of hard in make bestand zetten die de functies aanroept,
   zodat makefile set variabelen bovenin heeft die effectief config is.
   - SourceURL
   - DateOfSource
 - Kan make/bash bestand kijken of ES al bestanden heeft van dit land?
     - Zonee, upload deze dan
     - Zoja, verwijder dan deze voor dit land eerst, en voeg ze daarna toe


map structuur:
 - data/<land>/
    - <land>.raw.csv     zoals gedownload
    - <land>.clean.csv   klaar voor toJson
 - scripts/<land>/
    - cleanCSV.py        maakt van .nonull.csv het .clean.csv bestand

Bronnen:

https://www.youtube.com/watch?v=b7tCjZSvOno
Video met in beeld voorbeelden van gebruik tokenizer e.d. 

https://dev.to/aligoren/using-elasticsearch-with-python-and-flask-2i0e

https://blog.patricktriest.com/text-search-docker-elasticsearch/

https://github.com/triestpa/guttenberg-search

Requirements.txt & conda:
https://medium.com/@boscacci/why-and-how-to-make-a-requirements-txt-f329c685181e
