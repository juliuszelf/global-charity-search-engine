Doel:
Charitius 2.0
Een open data set van goede doelen pakken en deze zoekbaar maken.
Eerst alleen op titel, dan ook 'full-text' indexing.

Als het ok werkt, dan ook op Digital Ocean deployen. 
Als dat ok werkt, dan steeds meer open data toevoegen.
Geen webscraping, maar alleen van officiele bronnen.

USA2:
	- Makefile aanpassen 
		- ook die splits doen @done(2019-11-28)
		- upload met juiste variabele (gaat misschien vanzelf goed)
			- Bijna goed, maar doet ook es.json zelf
				- Eenvoudigste fix is 'if' in bash script test op 'es.json'
	- usa4 zit in andere landen, dat clean bestand moet anders
	- Meer csv bestanden, scripts lijken te werken, maar upload faalt
	usa/es.json faalt niet, dus iets is anders/fout aan usa2/es.json
	- TODO: check of uberhaubt juiste kolommen gepakt worden.

Flask:
  x Flask image maken
  - Flask image opschonen, niet copy . /app want volume mapping
  - Starten met docker-compose en volume mapping
      - In zelfde network ook Flask
      - Eerst met standaardserver van Flask
  - Basis pagina (van charitius code overnemen)
  - Flask laten praten met Elastic
  - Data uitlezen met Flask met Flask

Zoek verbeteren:
Mogelijke feature van zoekmachine is dat je veel kunt customizen
Dat je bijv. zelf fuzziness kunt selecteren, etc.
  - Land filteren
  - Fuzzy
  - Misschien tokenizen
  - Kibana voor monitoring kan ook nuttig zijn

Log:
   - Moet ook wegschrijven in een .log bestand 
     Dat bijhoudt waneer welk bestand gemaakt is e.d.

Betere scripts:
 - Opschonen scripts (alles met python argv paden)
 - Bewaar niet meer tussenstappen, maar wel het raw bestand?
   Liefst variant met copy met datum stamp
   Dus dat die backup wel bewaard blijft, maar niet bronbestand
 - SourceURL en SourceDate in een soort config bestand ergens zetten
   of hard in make bestand zetten die de functies aanroept,
   zodat makefile set variabelen bovenin heeft die effectief config is.
   - SourceURL
   - DateOfSource
 - Kan make/bash bestand kijken of ES al bestanden heeft van dit land?
     - Zonee, upload deze dan
     - Zoja, verwijder dan deze voor dit land eerst, en voeg ze daarna toe


map structuur:
 - data/<land>/
    - <land>.raw.csv     zoals gedownload
    - <land>.clean.csv   klaar voor toJson
 - scripts/<land>/
    - cleanCSV.py        maakt van .nonull.csv het .clean.csv bestand

Bronnen:

https://www.youtube.com/watch?v=b7tCjZSvOno
Video met in beeld voorbeelden van gebruik tokenizer e.d. 

https://dev.to/aligoren/using-elasticsearch-with-python-and-flask-2i0e

https://blog.patricktriest.com/text-search-docker-elasticsearch/

https://github.com/triestpa/guttenberg-search

Requirements.txt & conda:
https://medium.com/@boscacci/why-and-how-to-make-a-requirements-txt-f329c685181e
